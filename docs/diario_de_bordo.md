# Diario de Bordo – Atlas (Reinicio)

- 2025-10-15 14:33 BRT — Instrucao permanente: toda decisao ou implementacao deve ser registrada neste diario (`docs/diario_de_bordo.md`).
- 2025-10-15 15:02 BRT — Planejando estrutura do catálogo de origens legislativas para nova implementação.
- 2025-10-15 16:08 BRT — Criadas migrações `20251015160541_000_create_source_origins` e `20251015160705_001_seed_fonte_origem_goias` definindo a tabela `fonte_origem` e cadastrando a API de dados abertos da Casa Civil de Goiás como primeira origem.
- 2025-10-15 16:20 BRT — Ajustando plano do crawler para fase de descoberta (registro de metadados sem download).
- 2025-10-15 16:32 BRT — Plano do crawler ajustado para usar fonte_origem.id como chave de estratégia e seguir convenções LexML de URN.
- 2025-10-15 16:40 BRT — Plano Crawler Fase 1 documentado: 
  * Objetivo: descobrir atos e registrar metadados/URLs sem baixar conteúdo, seguindo URNs LexML (padrão br;<esfera>;<jurisdição>;<tipo_ato>;<AAAA-MM-DD>;<número>). 
  * Modelagem: tabelas `fonte_documento` (fila de descobertas) e `fonte_origem_execucao` (histórico de execuções). 

- 2025-10-16 13:37 BRT — Ajustado parser determinístico para remover citações de artigos/parágrafos, separar anexos (`QUADRO/ANEXO/TABELA`) e limpar textos dos dispositivos; validamos contra a portaria `br;go;estadual;portaria.orçamentária;2025-08-27;182`, obtendo 100% de match com o JSON do LLM e atualizando o status da sugestão `6378dc59-1055-4411-bb36-caab7701e95b` para `implementada`.

- 2025-10-16 13:45 BRT — Próximo alvo: sugestão `761da542-7dd8-462f-bfa2-bd4b18e8390d` (decreto nº 10747/2025). Plano: (1) reforçar o modo de alteração (`ALTERACAO_BLOCO_REGEX`) para agrupar filhos com `tipo="alteracao"` sob o artigo pai, (2) ajustar `SECAO_REGEX`/`SUBSECAO_REGEX` com lookahead que considera aspas `"”"`, (3) restringir `ARTIGO_REGEX` a inícios de linha dentro de blocos de alteração/cláusulas de revogação, e (4) incluir detecção de itens numerados (`ITEM_REGEX`) dedicados, com testes comparando a saída heurística ao JSON LLM registrado.
  * Arquitetura: orquestrador em `src/crawler/main.py` que lê origens ativas (`fonte_origem.id` como chave), instancia estratégias `discover()` em `src/crawler/strategies/`, e realiza UPSERT na fila com payload bruto em JSON. 
  * Configuração: flags CLI (`--origin-id`, `--since`, `--until`, `--limit`, `--dry-run`) para controlar períodos; logs estruturados por origem; registros de execução com contagem de novos/duplicados/falhas. 
  * Próximos passos: migrar tabelas de fila, implementar esqueleto do crawler, codificar estratégia de descoberta para a API Casa Civil Goiás, validar execução piloto (ex: janeiro/2025).
- 2025-10-15 16:26 BRT — Migração 002 aplicada: tabelas 'fonte_documento' e 'fonte_origem_execucao' criadas.
- 2025-10-15 16:35 BRT — Implementada infraestrutura inicial do crawler: utilitário de banco (), modelos (), registro de estratégias, estratégia  e orquestrador ; criada lista de dependências .
- 2025-10-15 16:35 BRT — Implementada infraestrutura inicial do crawler: utilitário de banco (`src/utils/db.py`), modelos (`src/crawler/types.py`), registro de estratégias, estratégia GoiasApiDiscovery e orquestrador (`src/crawler/main.py`); criado `requirements.txt`.
- 2025-10-15 16:55 BRT — Atualizada estratégia de descoberta para vincular diretamente o UUID da origem (`fd64e393-159f-4484-9ea4-e9437753791d`), removendo dependência de slugs e garantindo correspondência 1:1 entre `fonte_origem` e implementação.
- 2025-10-15 17:00 BRT — Estratégia renomeada para `src/crawler/strategies/fd64e393_159f_4484_9ea4_e9437753791d.py`, consolidando convenção de arquivos por UUID de `fonte_origem`.
- 2025-10-15 17:05 BRT — Crawler migrado para cliente oficial do Supabase (`supabase==2.4.6`): novo utilitário `src/utils/db.py` cria client REST, `src/crawler/main.py` passou a usar fetch/update/insert via API, `requirements.txt` atualizado para remover psycopg2.
- 2025-10-15 17:47 BRT — Dry-run do crawler executado com sucesso (5 atos listados para jan/2025, origem fd64e393-159f-4484-9ea4-e9437753791d).
- 2025-10-15 17:50 BRT — Crawler executado (origem fd64e393-159f-4484-9ea4-e9437753791d, jan/2025, limite 5): 5 registros novos inseridos em fonte_documento e execução registrada em fonte_origem_execucao.
- 2025-10-15 18:05 BRT — Ajustes na estratégia de Goiás: datas convertidas para ISO e `metadados_brutos` armazenado em JSON nativo (sem stringificação) garantindo persistência consistente em `fonte_documento`.
- 2025-10-15 18:18 BRT — Adicionado modo `--backfill` ao crawler: itera mês a mês em ordem decrescente até interrupção manual, registrando execuções com observação `backfill`.
- 2025-10-15 18:25 BRT — Planejado pipeline completo do crawler (descoberta → extração) com armazenamento de texto bruto em `textos_brutos`/Supabase, ajuste do PRD e revisão de `data_publicacao_diario`. Próximo passo: atualizar PRD, corrigir parsing da data e implementar modos `--extract` e fluxo padrão discovery+extract.
- 2025-10-15 18:35 BRT — Preparando etapa de extração: adicionar colunas na tabela `fonte_documento`, criar modo `--extract` (com `--limit`) e fluxo padrão discovery→extract; validação da data de publicação confirmada.
- 2025-10-15 18:37 BRT — Migração 003 aplicada: adicionadas colunas `caminho_texto_bruto`, `hash_texto_bruto`, `texto_extraido_em` em `fonte_documento` para rastrear a extração.
- 2025-10-15 18:45 BRT — Implementados `--extract`, `--discover-only` e pipeline padrão discovery→extract; backfill agora aciona extração automaticamente. Estratégia de Goiás passa a produzir texto bruto sanitizado (`conteudo_sem_formatacao`) e salvar em `textos_brutos/`. Dependências de storage adicionadas (`src/utils/storage.py`).
- 2025-10-15 18:47 BRT — Correção no upload do storage: flag `upsert` agora enviada como string e caminho relativo calculado para `textos_brutos/`. Próximo passo: rerodar `--extract` para validar gravação no bucket.
- 2025-10-15 18:50 BRT — Ajuste de path no storage: sanitização ASCII (slugify) aplicada aos componentes da URN para evitar erros `InvalidKey` no Upload.
- 2025-10-15 18:55 BRT — Iniciando planejamento do parser determinístico a partir dos textos brutos (bucket 'textos_brutos').
- 2025-10-15 19:02 BRT — Parser determinístico aprovado: tratamento específico fica na etapa de extração (crawler) e o parser consome sempre `.txt` do bucket; JSON resultante será salvo em novo bucket dedicado e acompanhado por campos de status no banco. Preparando PRD/migração conforme diretrizes.
- 2025-10-15 19:05 BRT — Migração 004 aplicada: adicionados status (`status_parsing`, `status_normalizacao`) e colunas (`caminho_parser_json`, hashes, timestamps) na tabela `fonte_documento` para rastrear parser e normalização.
- 2025-10-15 19:12 BRT — Implementado parser determinístico: novo módulo `src/parser` lê textos do bucket `textos_brutos/`, gera JSON inicial via estratégia por origem (Goiás) e publica em `textos_estruturados/`, atualizando `status_parsing`. Utilitários de storage/db expandidos para download/upload de JSON.
- 2025-10-15 19:15 BRT — Dry-run do parser executado para 20 atos: textos carregados de  e JSONs gerados com hashes registrados (sem persistência).
- 2025-10-15 19:15 BRT — Dry-run do parser executado para 20 atos da origem Goiás: leitura do bucket `textos_brutos` e geração de JSON estruturado (hashes registrados, sem persistência).
- 2025-10-15 19:20 BRT — Preparando aprimoramento do parser: segmentar o texto único em dispositivos (Art., parágrafos, incisos) usando regex e fallback heurístico.
- 2025-10-15 19:28 BRT — Parser agora genérico: removidas estratégias específicas, criado módulo determinístico com segmentação de Art./§/incisos/alíneas e logging detalhado dos dispositivos no CLI.
- 2025-10-15 19:31 BRT — CLI do parser agora exibe resumo dos dispositivos no terminal quando em modo --dry-run, facilitando depuração.
- 2025-10-16 10:05 BRT — Definido fluxo híbrido: parser determinístico roda padrão; amostras passam por revisão Gemini (modo "review") para medir divergências, coletar sugestões regex e bloquear ingestões abaixo de 100% de aderência.
- 2025-10-15 19:40 BRT — Identificadas duas necessidades: (1) quando um artigo altera outros dispositivos, manter seus rótulos originais (ex.: ‘Art. 3º …’) sem tratar como artigos sequenciais; (2) separar anexos do corpo principal e armazená-los em coleção própria.
- 2025-10-15 19:50 BRT — Estratégia acordada: executar parser determinístico e parser assistido por LLM (Gemini) em paralelo, comparar outputs para evolução das heurísticas, e gradualmente reduzir o uso do LLM para amostragem/validação.
- 2025-10-15 19:58 BRT — Iniciando integração do parser assistido por LLM (Gemini): armazenar JSON paralelo, comparar com saída determinística e registrar divergências.
- 2025-10-15 20:05 BRT — Parser agora suporta modos `--mode=deterministic|llm|both`: integra Geminine (`src/utils/llm.py`), compara saídas e salva JSON único em `textos_estruturados/`. Dependências atualizadas.
- 2025-10-16 11:05 BRT — Planejadas melhorias no parser determinístico: tratar blocos de alteração (“passa a vigorar...”) como filhos com `tipo=alteracao`, reconhecer seções/subseções/capítulos como dispositivos, ampliar regex (`Art. 51-A`, `Parágrafo único`) e separar o fecho (cidade/data/assinaturas) de forma genérica.
- 2025-10-16 11:40 BRT — Implementadas heurísticas revisadas em `src/parser/deterministic.py`: novos padrões LexML, extração recursiva de blocos `“...” (NR)`, isolamento de fecho em `disposicao_final` e atribuição de ordens preservando preâmbulo; describe_heuristics atualizado para refletir o conjunto.
- 2025-10-16 11:45 BRT — PRD atualizado na seção de pipeline para registrar a tabela `llm_parser_sugestao`, garantindo rastreabilidade das recomendações de melhoria enviadas pelo Gemini.
- 2025-10-16 12:05 BRT — CLI do parser (`src/parser/main.py`) passou a suportar amostragem no modo `review` via `--review-sample-ratio` (com seed opcional), permitindo definir a proporção de itens revisados pelo Gemini em execuções de backfill; PRD ajustado para refletir a estratégia.
- 2025-10-16 14:24 BRT — Iniciado ciclo de melhoria do parser para a sugestão `761da542-7dd8-462f-bfa2-bd4b18e8390d` (Decreto nº 10.747/2025): alinhar agrupamento de blocos `“...” (NR)` como filhos de `Art. 1º`, ajustar regex de seções/subseções em blocos de alteração, garantir rótulos limpos (sem `alteracao_X`) e preservar incisos numerados dentro das alterações; testes serão criados para evitar regressões.
- 2025-10-16 14:35 BRT — Implementadas heurísticas do parser para o Decreto nº 10.747/2025: blocos entre aspas com `(NR)` agora extraem rótulo + texto via `_rotulo_e_texto_alteracao`, eliminando `alteracao_X` e mantendo filhos com `tipo=alteracao`; lookahead de seções/subseções foi flexibilizado e prefixos (`o/a/os/as`) passaram a sinalizar citações, evitando artigos fantasmas em cláusulas de revogação. Criado teste `tests/test_parser_deterministic.py` validando o fluxo (execução: `python3 -m unittest tests.test_parser_deterministic`).
- 2025-10-16 14:51 BRT — Planejando simplificar o CLI do parser: manter apenas execução determinística por padrão e oferecer flag `--with-llm` para rodar LLM em paralelo; ao usar LLM, gerar automaticamente o comparativo, pedir sugestões via segundo prompt e registrar na `llm_parser_sugestao` sem amostragem nem modos especiais.
- 2025-10-16 14:55 BRT — CLI do parser simplificado: removidos modos `deterministic|llm|both|review` e amostragem; `--with-llm` agora executa o Gemini junto ao determinístico, compara as estruturas e registra sugestões diretamente na `llm_parser_sugestao` (sem bloquear o status). Guia do CLI atualizado e teste `python3 -m unittest tests.test_parser_deterministic` reexecutado após os ajustes.
- 2025-10-16 15:05 BRT — Decisão estratégica: suspender o parser determinístico e focar exclusivamente na geração via LLM para acelerar entregas; parser CLI será reescrito para depender apenas do Gemini e registrar o JSON final (sem heurísticas próprias). Determinístico e testes associados serão arquivados, mantendo o fluxo simples até revisitarmos regex no futuro.
- 2025-10-16 16:17 BRT — Limpeza dos buckets `textos_brutos/` e `textos_estruturados/`, reset dos campos em `fonte_documento` e processamento completo de 23 atos com a nova pipeline LLM-only (crawler `--extract --limit 10` seguido de `python -m src.parser.main` em lotes). Status atual: 23 registros `status_parsing=processado`, pronto para ampliar processamento em lote amanhã.
- 2025-10-22 14:55 BRT — Planejado pipeline completo Goiás (descoberta → armazenamento estruturado):
  * Descoberta & registro (`python -m src.crawler.main --origin-id fd64e393-159f-4484-9ea4-e9437753791d`): garantir origem ativa, executar janelas mensais (ou `--backfill`), capturar URNs e URLs oficiais, deduplicar com chave (origem, URN) e registrar execuções na `fonte_origem_execucao`.
  * Extração & storage (`--extract` automático pós-descoberta): baixar `conteudo_sem_formatacao`, higienizar quebras, calcular hash SHA256, subir para bucket `textos_brutos/` e atualizar `caminho_texto_bruto`, `texto_extraido_em`, `status=processado`.
  * Parsing LLM (`python -m src.parser.main --origin-id fd64e393-159f-4484-9ea4-e9437753791d`): ler textos brutos, chamar Gemini com heurísticas de contexto, produzir JSON estruturado contendo capítulos/títulos/artigos/parágrafos/incisos/anexos, salvar em `textos_estruturados/` e atualizar `status_parsing` + hashes.
  * Persistência estruturada: definir modelo transacional para atos/dispositivos/anexos (herdando metadados LexML), criar migracões correspondentes, escrever job de transformação que lê `caminho_parser_json`, desserializa o JSON e popula tabelas normalizadas (incluindo vínculos hierárquicos e trilha de auditoria) mantendo idempotência via hashes.
- 2025-10-22 16:20 BRT — Parsing LLM ajustado para gerar `id_lexml` por dispositivo (artigos, parágrafos, incisos, anexos). Resetado `status_parsing`/bucket `textos_estruturados/` e reprocessamento em lote em andamento (execuções contínuas `python -m src.parser.main --origin-id fd64e393-159f-4484-9ea4-e9437753791d --limit 10`). Backlog atual: 8.208 registros aguardando parsing; resultados já verificados amostralmente com IDs hierárquicos corretos. Próxima etapa: modelar e popular tabelas relacionais (ato_normativo, dispositivo, anexo) usando os novos identificadores.
- 2025-10-23 11:47 BRT — Crawler ganhou suporte a `--year`, permitindo backfill anual direto na API da Casa Civil Goiás sem combinar com `--since/--until`. Estratégia `GoiasApiDiscovery` agora aceita registros sem `link_download`, resolvendo URLs alternativas (`url_documento`, `arquivos`, `nid`) e registrando fallback; dry-run de 1989 passou a listar as URNs esperadas.
- 2025-10-23 11:55 BRT — Ajustado `fetch_descobertos_por_urns` para paginar URNs em lotes menores ao consultar o Supabase, evitando `HTTP 400` quando a estratégia anual insere dezenas de atos de uma vez antes da extração.
- 2025-10-23 11:58 BRT — Reorganizado front-end para deploy: `pnpm-lock.yaml` movido para a raiz, criado `pnpm-workspace.yaml` e `package.json` raiz com `packageManager`/`vercel-build`. Isso permite que o Vercel reconheça a versão do Next.js no monorepo `apps/atlas-grafo` e execute `pnpm install/build` automaticamente durante o `vercel build`.
- 2025-10-23 12:05 BRT — Parser ganhou filtros `--urn` e `--year`: o CLI agora permite reprocessar um documento específico (restrito a URNs informadas) ou limitar a execução a um ano (`data_legislacao`) sem manipular a fila manualmente. `fetch_para_parsing` passou a aceitar esses filtros e mantém o `--limit` apenas quando não há URNs explícitas.
- 2025-10-23 12:12 BRT — Crawler ajustado para aceitar `--urn` na fase de extração (`python -m src.crawler.main --extract --urn ...`). `run_extract` agora agrupa URNs específicas e/ou descobertas recentes por origem, evitando depender de `--limit` e retornando mensagem dedicada quando tudo já foi processado.
- 2025-10-23 12:18 BRT — Loader relacional também aceita `--urn`: `python -m src.loader.main --urn ...` passa a buscar apenas os atos indicados (sem limite) antes de inserir em `ato_normativo`/`dispositivo`. Repositório (`fetch_para_normalizacao`) atualizado para filtrar por URNs mantendo o comportamento anterior quando não há filtros.
- 2025-10-23 12:23 BRT — Corrigido loader para ignorar versões textuais sem conteúdo explícito: quando `versoes[].texto` vem `null`, reutilizamos o texto do dispositivo pai e garantimos `hash_texto`, evitando erro `23502` na tabela `versao_textual`.
- 2025-10-23 12:30 BRT — Parser ganhou logs de progresso por chunk: antes de enviar cada pedaço ao LLM registramos `chunk atual/total` e o tamanho do texto, facilitando acompanhar documentos longos como a Constituição/1989.
- 2025-10-23 12:36 BRT — Melhorado `chunking.gerar_chunks`: quando o LLM auxiliar não aponta limite seguro, quebramos o texto em um delimitador natural (`\n\n`, `\n`, espaço) e repetimos, evitando chunks gigantes (ex.: 500k caracteres) que faziam o LLM falhar.
- 2025-10-23 13:50 BRT — Reset nas configurações do Vercel: removidos `.vercel/` (raiz e app), `vercel.json` e o symlink `apps/atlas-grafo/pnpm-lock.yaml` para iniciar o setup do deploy do zero partindo da raiz. Posteriormente, toda a pasta `apps/` foi descartada e o `pnpm` (lock/workspace) limpo para retomarmos essa iniciativa em outra oportunidade.
- 2025-10-23 14:40 BRT — Plano para novo painel em Vercel (raiz):
  1. **Scaffold Next.js/React** – recolocar `package.json` na raiz com Next 16 + TypeScript, recriar `tsconfig`, `next.config` e estrutura `app/` para página inicial, layout e tema básico.
  2. **Integração Supabase** – configurar client compartilhado (`lib/supabase.ts`), definir API routes `/api/...` para operações administrativas (reprocessamento, estatísticas) e criar hooks SWR para dashboards.
  3. **Páginas do painel** – homepage com KPIs (totais por status, backlog), tela de execuções (`fonte_origem_execucao`), seção de logs (parser/loader) e painel de ações manuais (reset de status, disparo de scripts via supabase functions).
  4. **Autenticação/Acesso** – usar Supabase Auth (RLS) ou proteção simples via middleware (`NEXT_PUBLIC_ADMIN_TOKEN`) até termos um SSO definitivo.
  5. **Deploy** – `vercel link` apontando para a raiz, definir `Install`/`Build` (`pnpm install`, `next build`), configurar secrets (`SUPABASE_URL`, `SERVICE_ROLE`, chaves Gemini se necessário) e pipeline CI (preview em PR + produção).
- 2025-10-23 14:45 BRT — Criada estrutura Next.js mínima na raiz: `package.json` com scripts `dev|build|start`, `tsconfig.json`, `next.config.ts`, `next-env.d.ts` e diretório `app/` com `layout.tsx`, `globals.css` e `page.tsx` placeholder informando que o painel está em desenvolvimento.
- 2025-10-23 14:07 BRT — Ajustado `GraphDatabase.driver(...)` do sincronizador para deixar que o driver defina a criptografia de acordo com o esquema (`neo4j+s`), evitando `ConfigurationError` quando usado com Aura.
- 2025-10-22 16:25 BRT — Criada migração `20251022162500_006_create_normative_schema.sql` definindo as tabelas relacionais: `ato_normativo`, `dispositivo`, `anexo`, `dispositivo_relacao` e `versao_textual`, além dos enums `tipo_dispositivo` e `tipo_relacao_normativa`. Estrutura cobre vínculos hierárquicos via `id_lexml`, armazenamento de anexos e controle de versões textuais. Próximo passo: implementar loader que lê `caminho_parser_json`, popula essas tabelas de forma idempotente e marca atos como normalizados.
- 2025-10-22 17:25 BRT — Implementado loader relacional (`python -m src.loader.main`): `src/loader/main.py` (CLI) e `src/loader/repository.py` (operações Supabase) transformam JSONs estruturados em `ato_normativo`, `dispositivo`, `anexo`, `dispositivo_relacao`, `versao_textual`. Execução inicial (`--limit 10`) normalizou 9 atos (Goiás) inserindo 10 `ato_normativo`, 207 `dispositivo`, 2 `anexo`; `status_normalizacao` atualizado para `processado`. Backlog restante: 8.198 registros pendentes; loader suporta `--dry-run`, `--limit` e idempotência (limpa componentes por ato antes de reescrever). Próximo passo: automatizar lotes maiores e evoluir persistência de relações/versões quando disponíveis no JSON.
- 2025-10-22 17:28 BRT — Próxima etapa definida: aplicar LLM para inferir relações normativas (`altera`, `revoga`, etc.) e versões textuais (vigência histórica) diretamente dos textos/parágrafos, pois regex não alcança a diversidade de redações. Planejar prompts e armazenamento no JSON estruturado antes de popular `dispositivo_relacao`/`versao_textual`.
- 2025-10-22 18:10 BRT — Status unificado do pipeline implementado: novo helper `src/utils/status.py` calcula `status` consolidado (descoberto/processado/parsing/normalizado). Parser atualiza `status` ao concluir o JSON; loader faz o mesmo ao normalizar. Criado CLI `python -m src.loader.sync_status` para recalcular a coluna em lote. Execução inicial converteu registros normalizados para `status=normalizado`; backlog restante permanece como `processado` até finalizar parsing/loader.
- 2025-10-22 18:36 BRT — Pipeline resetado para reprocessar etapa LLM: removidos JSONs de `textos_estruturados/`, limpas tabelas relacionais (`ato_normativo`, `dispositivo`, `anexo`, `versao_textual`, `dispositivo_relacao`) e campos de parsing/normalização em `fonte_documento` foram resetados (`status_parsing`/`status_normalizacao` = `pendente`, `status` alinhado com presença de texto bruto). Prompt do LLM atualizado (`src/utils/llm.py`) para obrigar retorno de `fonte.titulo` e `fonte.situacao_vigencia`; heurísticas locais removidas para que o título/vigência venham diretamente do modelo.
- 2025-10-22 19:08 BRT — Planejamento da próxima etapa: usar LLM adicional para (1) extrair relações normativas (altera/revoga/regulamenta) entre dispositivos, (2) identificar versões textuais e intervalos de vigência. Tarefas preliminares: definir prompt específico e formato do payload (`estruturas.relacoes` e `estruturas.versoes` no JSON), ajustar o parser para persistir esses arrays e evoluir o loader para popular `dispositivo_relacao`/`versao_textual` quando presentes. Avaliar necessidade de amostragem/testes manuais antes de rodar em lote.
- 2025-10-22 19:32 BRT — Prompt do parser atualizado (`src/utils/llm.py`) para contemplar hierarquias LexML completas (Partes, Livros, Títulos, Capítulos, Seções, Subseções), retorno obrigatório de `relacoes` e `versoes` por dispositivo e relações no nível raiz. Loader estendido para resolver duplicidades de `id_lexml`, mapear relações por rótulo e preparar inserção futura em `dispositivo_relacao`/`versao_textual`. Próximo passo: validar saída do LLM em amostra e, se consistente, ativar gravação das relações/versões no banco.
- 2025-10-22 20:04 BRT — Revisado `docs/graph_rag.pdf` e mapeado próximos desafios: (1) gerar Text Units acumulados e versões como agregações (sem duplicação), com metadados de vigência; (2) criar Text Units para ações normativas e metadados estruturados (URN, status, sucessões); (3) incorporar temas/comunidades no grafo; (4) construir o Knowledge Graph + base vetorial integrando estrutura/temporalidade; (5) implementar retrieval hierárquico + semântico e plano de avaliação. Pipeline atual atende ingestão/parsing, e seguir para essas frentes nos aproxima do Graph RAG completo descrito no artigo.
- 2025-10-22 20:15 BRT — Normalizado mapeamento de `tipo` nas relações normativas: loader agora converte sinônimos produzidos pelo LLM (ex.: “referência”, “remissão”) para os valores do enum `tipo_relacao_normativa` e ignora rótulos desconhecidos com log. Prompt do parser reforçado para exigir exatamente os seis valores aceitos, reduzindo respostas fora do padrão.
- 2025-10-22 20:32 BRT — Plano para visualização interativa no Vercel: (1) criar front-end Next.js hosteado no Vercel com rota API protegida pelo service role do Supabase; (2) montar grafo usando `react-force-graph` exibindo atos (nós) e relações (arestas) com filtros por tipo de relação, período e órgão; (3) adicionar painel lateral com detalhes do dispositivo selecionado (texto, vigência, links para o bucket); (4) automatizar deploy via GitHub (`atlas-ceigep`) e configurar secrets (`SUPABASE_URL`, `SUPABASE_SERVICE_ROLE_KEY`); (5) documentar fluxo de publicação e futuras extensões (clustering por temas e timeline). Próximo passo: iniciar repositório web ou subpasta `apps/atlas-grafo` com esse MVP.
- 2025-10-22 21:05 BRT — Implementado app web `apps/atlas-grafo`: scaffold Next.js + TypeScript com `pnpm`, dependências (`@supabase/supabase-js`, `react-force-graph`, `swr`) e rota `api/graph` que agrega `dispositivo_relacao` + metadados de `ato_normativo`. Criado componente `GraphExplorer` com filtros por tipo de relação, detalhes contextualizados e resize automático. Build validado (`pnpm build` com env fake) e documentação atualizada em `apps/atlas-grafo/README.md` (passo-a-passo local/Vercel + secrets). `.env.example` adicionado para configurar `SUPABASE_URL`/`SUPABASE_SERVICE_ROLE_KEY`.
- 2025-10-22 21:22 BRT — Corrigido erro de runtime `AFRAME is not defined`: substituí `react-force-graph` por `react-force-graph-2d` e ajustei o `GraphExplorer` para carregar o componente via dynamic import específico, eliminando a dependência VR. Build (`pnpm build`) passou novamente com sucesso.
- 2025-10-22 21:28 BRT — Adicionado retry com backoff exponencial (0,5s → 2s) em `src/utils/storage.upload_text` para tolerar erros 502 do Supabase Storage durante o upload dos textos brutos. Pipeline de backfill pode continuar sem intervenção manual em casos transitórios.
- 2025-10-22 21:30 BRT — Loader ajustado (`src/loader/main.py`) para garantir que `texto` dos dispositivos nunca seja `NULL` ao persistir (`dispositivo`). Quando o LLM não fornece texto, gravamos string vazia e prosseguimos com o restante da estrutura.
- 2025-10-22 21:35 BRT — Crawler ganhou flag `--append-only`: ao ativar, o fluxo de descoberta/backfill não atualiza registros existentes (apenas insere inéditos). `processar_origem` e `run_backfill` propagam essa opção para `inserir_descoberta`, permitindo executar backfills “read-only” sobre itens já cadastrados.
- 2025-10-22 21:45 BRT — Criado utilitário `scripts/debug_llm_response.py` para depurar saídas problemáticas do LLM: dado `--origin-id` e `--urn`, baixa o texto bruto, executa o Gemini e imprime/salva o JSON bruto antes do `json.loads`, permitindo corrigir manualmente respostas inválidas antes de integrar ajustes definitivos no parser.
- 2025-10-23 09:35 BRT — Plano definido para chunking seguro no parser LLM: (1) limitar requisições por orçamento de tokens; (2) usar modelo auxiliar para indicar o último dispositivo completo dentro do trecho (sem heurísticas); (3) gerar chunks sequenciais sem cortar dispositivos; (4) rodar parser principal por chunk; (5) mesclar JSONs resultantes e recalcular `id_lexml`; (6) registrar hashes por chunk e validar concatenção do texto integral. Próximos passos: implementar essa divisão com reprocessamento/resumo e garantir retomada idempotente por chunk.

- 2025-10-23 09:05 BRT — Parser agora realiza até duas tentativas ao chamar o Gemini. Em caso de `JSONDecodeError` ou falha na extração do bloco JSON, a função loga o erro (`logging.warning`) e repete a solicitação antes de desistir. Isso reduz quedas causadas por respostas malformadas sem necessidade de intervenção manual.

- 2025-10-23 09:10 BRT — Loader atualizado para usar upsert em `versao_textual`, evitando erro 409 quando a combinação (dispositivo_id, hash_texto) já está presente.

- 2025-10-23 10:55 BRT — Implementado chunking no parser LLM (`src/parser/chunking.py`): textos extensos agora são divididos em trechos seguros com auxílio do Gemini auxiliar, processados em sequência e recombinados antes da normalização. Loader ajustado para `versao_textual` usar upsert e truncar `rotulo`, evitando conflitos; crawler passou a extrair apenas os itens descobertos no período atual. Visualizador Next.js ganhou endpoint `/api/act`, filtro por ato específico e exibição do texto integral dos dispositivos.

- 2025-10-23 11:02 BRT — Crawler ajustado para pular a etapa de extração quando nenhuma descoberta nova ocorre no intervalo, evitando baixar textos pendentes de outros períodos (anterior a refinamento do filtro por URNs).
